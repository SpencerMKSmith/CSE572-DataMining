
% Read in all of the feature values
allData = csvread('completeFeatureMatrix.csv', 1);
classifications = allData(:,2);
featureValues = allData(:,3:end);

% Read in the group data
groupMappings = importGroupMapping();

% Here add a column to allData that will hold the groupId
% TODO: This

% Here loop through each row in allData (NOT GROUP MAPPING).  Get the file Id, find the corresponding groupId from the groupMappings
%   and set the value in the new column (Be sure to convert to number as the matrix is numeric i.e Group_01 -> 1)
% TODO: This

% Get each fileId
% TODO: Change to groupIds, we want to take each groupId, just refactor "fileIds" to "groupIds" and point to the new column
%       instead of column 1
fileIds = unique(allData(:,1));

%
% PHASE 1
%

% Set up the output file
phase1FileName = 'phase1Output.csv';
dlmwrite(phase1FileName, ('fileId, dtAcc, dtPrec, dtRec, dtF1, dtROC, svmAcc, svmPrec, svmRec, svmF1, svmROC, nnAcc, nnPrec, nnRec, nnF1, nnROC'), '');

% Create matrix that will be appended to the output file
metricsForFile = zeros(1, 16); 

% For each file we will split into test and train
for fileIndex = 1:length(fileIds)
    currentFileId = fileIds(fileIndex,1);
    
    % Get all data for the file
    includeRowList = allData(:, 1) == currentFileId;    % True/False list if the row has the value from the current file
    dataFromFile = allData(includeRowList, :);             % Use the true/false list to select the rows we want
    
    % Determine the number of train and test rows
    numberOfTrainRows = ceil(length(dataFromFile) * .6);
    
    % Split 60% of records into train data
    trainData = dataFromFile(1:numberOfTrainRows,:);
    trainFeatureData = trainData(:, 3:end); % Feature data values
    trainClassifications = trainData(:, 2); % Single column containing the classification values
    
    % Take the rest as test data
    testData = dataFromFile(numberOfTrainRows + 1:end, :);
    testFeatureData = testData(:, 3:end); % TODO: Be sure to update this when the new grou column is added
    testClassifications = testData(:, 2); % TODO: Be sure to update this when the new grou column is added
    
    % This will hold all of the data for the file and will be appended to the output file
    metricsForFile = zeros(1, 16); 
    metricsForFile(1,1) = currentFileId;
    
    %
    % Decision Tree
    %
    
    if currentFileId == 1503512621910
        disp("something")
    end

    % Train the decision tree for the data
    % TODO: There are many parameters that can be added here, add some, run it and see if the accuracy/precision/recall is increased
    %       Will need to run a good number of times to see what works best or if it doesn't make a difference.  Do same with SVM and NN.
    %       Be sure to understand the best parameters chosen as we will need to talk about them in the write up.
    decisionTree = fitctree(trainFeatureData, trainClassifications); % First parameter is the feature values, second are the classifications
    
    % Use the test data to predict
    [dtPredictedValues, scores] = predict(decisionTree, testFeatureData);
    
    % Analyze the performance of the predicted values
    [ dtAccuracy, dtPrecision, dtRecall, dtF1, dtROC ] = AnalyzePredictor(testClassifications, dtPredictedValues, scores(:, 2));
    
    % Add the values for the decision tree to the output matrix
    metricsForFile(1, 2) = dtAccuracy;
    metricsForFile(1, 3) = dtPrecision;
    metricsForFile(1, 4) = dtRecall;
    metricsForFile(1, 5) = dtF1;
    metricsForFile(1, 6) = dtROC;

    %
    % SVM
    %
    
    % Train an SVM
    svm = fitcsvm(trainFeatureData, trainClassifications, 'Standardize',true, 'KernelScale','auto'); % TODO: Play around/remove the values as needed
    
    % Use the test data to predict values
    [svmPredictedValues, scores] = predict(svm, testFeatureData);
    
    % Analyze the performance of the predicted values
    [ svmAccuracy, svmPrecision, svmRecall, svmF1, svmROC ] = AnalyzePredictor(testClassifications, svmPredictedValues, scores(:, 2));
    
    % Add the values for the decision tree to the output matrix
    metricsForFile(1, 7) = svmAccuracy;
    metricsForFile(1, 8) = svmPrecision;
    metricsForFile(1, 9) = svmRecall;
    metricsForFile(1, 10) = svmF1;
    metricsForFile(1, 11) = svmROC;
    
    % 
    % Neural Network
    %
    
    % TODO: Create the neural network
    %{
    % Create and train a neural network using the NN toolbox
    nn = % Some neural network created using the toolbox
    
    % Use the test data to predict values
    [nnPredictedValues, scores] = predict(nn, testFeatureData); % Needs to return the predictions and the probability scores
    
    % Analyze the performance of the predicted values
    [ nnAccuracy, nnPrecision, nnRecall, nnF1, nnROC ] = AnalyzePredictor(testClassifications, nnPredictedValues, scores(:, 2)); % Make sure to pass the probability that "1" is given
    
    % Add the values for the decision tree to the output matrix
    metricsForFile(1, 12) = nnAccuracy;
    metricsForFile(1, 13) = nnPrecision;
    metricsForFile(1, 14) = nnRecall;
    metricsForFile(1, 15) = nnF1;
    metricsForFile(1, 16) = nnROC;    
    %}
    
    % After performing analysis of the three different methods, write to the output file
    dlmwrite(phase1FileName, metricsForFile, 'delimiter', ',', '-append', 'precision', 13);

end

%
% PHASE 2
%

% Choose 10 groups to use as sampling
trainingGroups = fileIds([1, 4, 8, 9, 12, 13, 17, 18, 20, 22, 23, 30], :); % Pretty much just random values

% Get all of the training data from the above groups
% TODO: Be sure to update column index when new column is added
trainingGroupRows = ismember(allData(:, 1), trainingGroups); % True/False values of what rows to choose
p2TrainingData = allData(trainingGroupRows, :);                % Use the true/false list to select the rows we want
p2TrainFeatureData = p2TrainingData(:, 3:end); % TODO: Be sure to update this when the new grou column is added
p2TrainClassifications = p2TrainingData(:, 2); % TODO: Be sure to update this when the new grou column is added

% Determine the test groups, simply the values that weren't selected above
testGroups = fileIds(~ismember(fileIds, trainingGroups), :); 

% First we will train each of the classifiers then we will run the test data from each group through them

% Create the decision tree
% TODO: Play around with the parameters (may not be the same as above)
decisionTree2 = fitctree(p2TrainFeatureData, p2TrainClassifications); % First parameter is the feature values, second are the classifications

% Create the SVM
% TODO: Play around with the parameters
svm2 = fitcsvm(p2TrainFeatureData, p2TrainClassifications); % TODO: Play around/remove the values as needed

% Train the NN
% TODO: Use nn toolbox

% For each test group
for fileIndex = 1:length(testGroups)
	testGroupId = testGroups(fileIndex, 1);
    
    % This will hold output metrics for each test value
    phase2Metrics = zeros(1, 16); 
    phase2Metrics(1, 1) = testGroupId;
    
    % Get the test data for this group
    % TODO: Be sure to update column index when new column is added
    includeRowList = allData(:, 1) == testGroupId;    % True/False list if the row has the value from the current file
    p2TestData = allData(includeRowList, :);             % Use the true/false list to select the rows we want
    p2TestFeatures = p2TestData(:, 3:end);      % TODO: Update if column index changes
    p2TestClassifications = p2TestData(:, 2);   % TODO: Update if column index changes
    
    % Run the test data through each classifier and get metrics
    
    % Decision tree predictor
    [dtPredictedValues, scores] = predict(decisionTree2, p2TestFeatures);
    
    % Analyze the performance of the predicted values
    [ dtAccuracy, dtPrecision, dtRecall, dtF1, dtROC ] = AnalyzePredictor(p2TestClassifications, dtPredictedValues, scores(:, 2));
    
    % Add the values for the decision tree to the output matrix
    phase2Metrics(1, 2) = dtAccuracy;
    phase2Metrics(1, 3) = dtPrecision;
    phase2Metrics(1, 4) = dtRecall;
    phase2Metrics(1, 5) = dtF1;
    phase2Metrics(1, 6) = dtROC;

    % Run test data through SVM predictor
    
    svm = fitcsvm(trainFeatureData, trainClassifications, 'Standardize',true, 'KernelScale','auto'); % TODO: Play around/remove the values as needed
    
    % Use the test data to predict values
    [svmPredictedValues, scores] = predict(svm, p2TestFeatures);
    
    % Analyze the performance of the predicted values
    [ svmAccuracy, svmPrecision, svmRecall, svmF1, svmROC ] = AnalyzePredictor(p2TestClassifications, svmPredictedValues, scores(:, 2));
    
    % Add the values for the decision tree to the output matrix
    phase2Metrics(1, 7) = svmAccuracy;
    phase2Metrics(1, 8) = svmPrecision;
    phase2Metrics(1, 9) = svmRecall;
    phase2Metrics(1, 10) = svmF1;
    phase2Metrics(1, 11) = svmROC;
    
    % Run test data through NN predictor
    
    % TODO: Create the neural network
    %{
    % Create and train a neural network using the NN toolbox
    nn = % Some neural network created using the toolbox
    
    % Use the test data to predict values
    [nnPredictedValues, scores] = predict(nn, p2TestFeatures); % Needs to return the predictions and the probability scores
    
    % Analyze the performance of the predicted values
    [ nnAccuracy, nnPrecision, nnRecall, nnF1, nnROC ] = AnalyzePredictor(p2TestClassifications, nnPredictedValues, scores(:, 2)); % Make sure to pass the probability that "1" is given
    
    % Add the values for the decision tree to the output matrix
    phase2Metrics(1, 12) = nnAccuracy;
    phase2Metrics(1, 13) = nnPrecision;
    phase2Metrics(1, 14) = nnRecall;
    phase2Metrics(1, 15) = nnF1;
    phase2Metrics(1, 16) = nnROC;    
    %}
    
    % After performing analysis of the three different methods, write to the output file
    dlmwrite(phase1FileName, metricsForFile, 'delimiter', ',', '-append', 'precision', 13);

end




